<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="static/style.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/light.css">
  <meta charset="UTF-8">
  <style>
    #container {
      display: flex;
      align-items: flex-start;
    }
    #image-section {
      flex: 0 0 200px; /* Adjust the width as needed */
      margin-right: 20px;
    }
    #image-section img {
      width: 100%;
      height: auto;
      border-radius: 5px;
    }
    #info-section {
      flex: 1;
    }
    .profile-links {
      display: flex;
      gap: 10px;
    }
    .profile-links a {
      display: inline-flex;
      align-items: center;
      text-decoration: none;
      color: inherit;
    }
    .profile-links svg {
      width: 24px;
      height: 24px;
      margin-right: 5px;
    }
  </style>
</head>
<body>
  <!-- Intro -->
  <div id="container">
    <div id="image-section">
      <img src="your-photo.jpg" alt="Ava Kouhana">
    </div>
    <div id="info-section">
      <h2><strong>Ava Kouhana </strong></h2>
      <p>
        <strong>akouhana (at) stanford.edu</strong> 
      </p>
      <p>
      I am a French master's student specializing in Artificial Intelligence and Statistics. Before commencing my research at Stanford University, I dedicated six months to 
conducting research at Harvard University's Ophthalmology Department. During this time, my focus was primarily on Computer Vision tasks (Image Segmentation, Vision-Language 
Models), as well as Diffusion models.
      </p>
      <p>
      I am pleased to have joined Stanford in February 2024 for a six-month research opportunity in the Radiology Department under the 
supervision of Dr. Craig Levin where I worked primarily on Super-Resolution leveraging Latent Diffusion Models. From September 2024, I am fortunate to joining Stanford for the 
ICME ( Computational and Mathematical Engineering ) Master's degree.
      </p>
      <div class="profile-links">
        <a href="https://profiles.stanford.edu/intranet/ava-kouhana?tab=bio">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M21 16V8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16z"></path>
            <polyline points="3.27 6.96 12 12.01 20.73 6.96"></polyline>
            <line x1="12" y1="22.08" x2="12" y2="12"></line>
          </svg>
          Stanford Profile
        </a>
        <a href="https://scholar.google.com/citations?user=nxESuB0AAAAJ&hl=fr">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M12 14l9-5-9-5-9 5 9 5z"></path>
            <path d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z"></path>
            <path d="M12 14l-6.16-3.422a12.083 12.083 0 00-.665 6.479A11.952 11.952 0 0112 20.055a11.952 11.952 0 016.824-2.998 12.078 12.078 0 00-.665-6.479L12 14z"></path>
          </svg>
          Google Scholar
        </a>
        <a href="https://www.linkedin.com/in/yonatano/">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
            <rect x="2" y="9" width="4" height="12"></rect>
            <circle cx="4" cy="4" r="2"></circle>
          </svg>
          LinkedIn
        </a>
      </div>
    </div>
  </div>

  <!-- Papers -->
  <div id="container">
    <div id="papers-section">
      <h3>Papers</h3>
      <ul>
        <li>
          <h4 class="paper-title"><a href="https://openreview.net/pdf?id=qNrJJZAKI3">FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning 
	Using Segment Anything Model with Fair Error-Bound Scaling</a></h4>
          <p class="co-authors">Yu Tian*, Min Shi*,Yan Luo*,<strong> Ava Kouhana</strong>,Tobias Elze,Mengyu Wang. ICLR 2024.</p>
        </li>
        <li>
          <h4 class="paper-title"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Luo_FairCLIP_Harnessing_Fairness_in_Vision-Language_Learning_CVPR_2024_paper.pdf">FairCLIP: Harnessing 
	Fairness in Vision-Language Learning</a></h4>
          <p class="co-authors">Yan Luo* ,Min Shi*, Muhammad Osama Khan* ,Muhammad Muneeb Afzal, Hao Huang, Shuaihang Yuan,Yu Tian,Luo Song,<strong>Ava Kouhana</strong>, Tobias Elze, Yi Fang,Mengyu 
	Wang. CVPR 2024.</p>
        </li>
      </ul>
    </div>
  </div>

  <!-- Projects -->
  <!-- <div id="container">
    <div id="projects-section">
      <h3>Software / Projects</h3>
      <ul>
      </ul>
    </div>
  </div> -->

  <!-- Writing -->
  <!-- <div id="container">
    <div id="writing-section">
      <h3>Writing</h3>
      <ul>
      </ul>
    </div>
  </div> -->

  <!-- Misc -->
  <!-- <div id="container">
    <div id="misc-section" style="margin-bottom: 25px">
      <h3>Misc</h3>
    </div>
  </div> -->

  </div>

</body>
</html>
